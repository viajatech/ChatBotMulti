#David Ruiz (@viajatech)
#Licencia APACHE 2.0

#Si utilizas mi script recuerda dar créditos (Apache 2.0) 
#Se agradece tu estrellita en el repo de github
#https://github.com/viajatech


import os
import random
import asyncio
from langdetect import detect
import gradio as gr
import torch
from PIL import Image
from transformers import MllamaForConditionalGeneration, AutoProcessor, set_seed
from datetime import datetime
from dateutil import tz
import requests
from geopy.geocoders import Nominatim
import feedparser
from torchvision import models, transforms

# Asegúrate de definir tu token de Hugging Face en la variable de entorno HF_TOKEN
HF_TOKEN = os.getenv("HF_TOKEN", "tu_token_aquí")

model_id = "meta-llama/Llama-3.2-11B-Vision"
print("Cargando el modelo y el procesador...")

model = MllamaForConditionalGeneration.from_pretrained(
    model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    token=HF_TOKEN
)
processor = AutoProcessor.from_pretrained(model_id, token=HF_TOKEN)
print("Modelo cargado exitosamente.")

geolocator = Nominatim(user_agent="my_geocoder")

# Cargar un modelo de clasificación de imágenes pre-entrenado (ResNet50)
classification_model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2).eval()
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
      mean=[0.485, 0.456, 0.406],
      std=[0.229, 0.224, 0.225]
    )
])

# Etiquetas de ImageNet
imagenet_url = "https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
imagenet_classes = requests.get(imagenet_url).text.strip().split("\n")

def classify_image(img_path):
    img = Image.open(img_path).convert("RGB")
    input_tensor = preprocess(img).unsqueeze(0)
    with torch.no_grad():
        output = classification_model(input_tensor)
    probs = torch.nn.functional.softmax(output, dim=1)
    top5_probs, top5_idxs = probs.topk(5)
    top5 = [(imagenet_classes[idx], float(prob)) for idx, prob in zip(top5_idxs[0], top5_probs[0])]
    return top5

def set_random_seed_wrapper(seed):
    if seed is not None and seed.strip().isdigit():
        seed = int(seed)
        set_seed(seed)
        random.seed(seed)
        torch.manual_seed(seed)
        if torch.cuda.is_available():
            torch.cuda.manual_seed_all(seed)

def detect_language(text):
    try:
        lang = detect(text)
    except:
        lang = 'es'
    if lang not in ['en', 'es']:
        lang = 'es'
    return lang

def build_prompt(user_name, chatbot_name, story_context, conversation_history, user_input, language, internet_enabled):
    instructions = f"""
INSTRUCCIONES DEL SISTEMA (NO IGNORAR):

- Eres el asistente "{chatbot_name}" (assistant).
- El usuario se llama "{user_name}" (user).
- No escribas como si fueras el usuario.
- Responde en el mismo idioma del usuario.
- No desvíes el tema, responde las peticiones del usuario.
- Mantén el contexto inicial y el historial.
- Usa todos los tokens solicitados (min_new_tokens = max_new_tokens) para una respuesta completa y coherente.
- No mezclar roles, no inventar líneas del usuario.
- Si internet_enabled es True, puedes:
  - Obtener hora/fecha desde 'http://worldtimeapi.org/api/ip'
  - Obtener clima con 'wttr.in/<lugar>?format=3'
  - Obtener noticias desde RSS público (BBC: 'https://feeds.bbci.co.uk/news/rss.xml')
  - Obtener imágenes desde 'loremflickr.com' sin API key.
    * Vista previa: 'https://loremflickr.com/320/240/<query>'
    * Imagen grande: 'https://loremflickr.com/1600/900/<query>'
  - Descarga la imagen grande, guárdala como 'imagen_descargada.jpg', y muéstrala con:
    `![imagen](imagen_descargada.jpg)`
  - Verifica el contenido de la imagen con un modelo de clasificación, e informa si coincide con lo solicitado.
  - Si falla la descarga, informar al usuario.
- No terminar abruptamente.

Contexto inicial:
{story_context}

Historial de la conversación:
"""
    for msg in conversation_history:
        instructions += f"\n{msg['content']}"
    prompt = f"{instructions}\n{user_name}: <|begin_of_text|>{user_input}\n{chatbot_name}:"
    return prompt.strip()

def get_current_time_internet():
    try:
        r = requests.get("http://worldtimeapi.org/api/ip", timeout=5)
        if r.status_code == 200:
            data = r.json()
            datetime_str = data.get("datetime", "")
            return datetime_str
    except:
        pass
    # Si falla, hora local
    now = datetime.now(tz=tz.gettz('UTC')).astimezone(tz=None)
    return now.strftime("%Y-%m-%d %H:%M:%S %Z")

def get_weather(place):
    try:
        r = requests.get(f"https://wttr.in/{place}?format=3", timeout=5)
        if r.status_code == 200:
            return r.text.strip()
    except:
        pass
    return "No se pudo obtener el clima."

def get_news():
    feed = feedparser.parse("https://feeds.bbci.co.uk/news/rss.xml")
    if 'entries' not in feed or not feed['entries']:
        return "No se encontraron noticias."
    results = []
    for entry in feed['entries'][:3]:
        title = entry.get('title', 'Sin título')
        link = entry.get('link', '')
        results.append(f"{title} - {link}")
    return "\n".join(results)

def search_places_osm(address, query="cafe"):
    try:
        location = geolocator.geocode(address, timeout=10)
        if not location:
            return "No se encontró la dirección."
        lat, lon = location.latitude, location.longitude
        overpass_url = "http://overpass-api.de/api/interpreter"
        radius = 1000
        overpass_query = f"""
        [out:json];
        node
          ["amenity"="{query}"]
          (around:{radius},{lat},{lon});
        out;
        """
        response = requests.get(overpass_url, params={'data': overpass_query}, timeout=10)
        if response.status_code != 200:
            return "No se pudo acceder a la API de Overpass."
        data = response.json()
        if 'elements' not in data or not data['elements']:
            return f"No se encontraron lugares cercanos para '{query}'."
        results = []
        for elem in data['elements'][:3]:
            name = elem['tags'].get('name', 'Desconocido')
            results.append(f"{name} - Coordenadas: {elem['lat']}, {elem['lon']}")
        return "\n".join(results)
    except:
        return "Error buscando lugares."

def extract_image_keyword(user_input):
    user_words = user_input.lower().split()
    keywords = ["imagen", "foto", "picture", "photo", "image", "pic"]
    for i, w in enumerate(user_words):
        if w in keywords and i+1 < len(user_words):
            query_terms = user_words[i+1:]
            return "_".join(query_terms)
    return "_".join(user_words)

def download_image(query):
    preview_url = f"https://loremflickr.com/320/240/{query}"
    large_url = f"https://loremflickr.com/1600/900/{query}"

    print("Intentando descargar:", large_url)
    try:
        r = requests.get(large_url, timeout=10)
        if r.status_code == 200:
            img_path = "imagen_descargada.jpg"
            with open(img_path, 'wb') as f:
                f.write(r.content)
            print("Imagen descargada con éxito:", img_path)
            return img_path, preview_url
        else:
            print("No se pudo descargar la imagen, status code:", r.status_code)
    except Exception as e:
        print("Error descargando la imagen:", e)
    return None, None

def check_image_relevance(img_path, requested_object):
    # Clasificar la imagen
    top5 = classify_image(img_path)
    # Revisar si el objeto pedido aparece en las top5 predicciones del modelo
    # Esto es una heurística, ya que el modelo clasifica en categorías ImageNet,
    # no siempre exactas a "perro", "gato", etc. Pero es una aproximación.
    requested_object = requested_object.lower()
    found = False
    for cls_name, prob in top5:
        if requested_object in cls_name.lower():
            found = True
            break
    return found, top5

async def generate_response(user_input, user_name, chatbot_name, story_context, seed_input, max_new_tokens, temperature, top_p, repetition_penalty, state, internet_toggle):
    if state is None:
        state = {
            'conversation_history': [],
            'user_name': user_name or "Usuario",
            'chatbot_name': chatbot_name or "Asistente",
            'story_context': story_context or "",
            'seed': seed_input,
            'language': 'es',
            'reward_score': 0.0,
            'punishment_score': 0.0
        }
    else:
        if user_name:
            state['user_name'] = user_name
        if chatbot_name:
            state['chatbot_name'] = chatbot_name
        if story_context is not None:
            state['story_context'] = story_context
        if seed_input:
            state['seed'] = seed_input

    language = detect_language(user_input)
    state['language'] = language

    set_random_seed_wrapper(state['seed'])

    adjusted_temperature = float(temperature)
    if adjusted_temperature < 0.1:
        adjusted_temperature = 0.1
    adjusted_repetition_penalty = float(repetition_penalty)

    max_new_tokens = int(max_new_tokens)
    if max_new_tokens < 1:
        max_new_tokens = 20
    min_new_tokens = max_new_tokens

    internet_enabled = (internet_toggle == True)

    additional_info = ""
    user_input_lower = user_input.lower()

    requested_object = None

    if internet_enabled:
        # Hora/fecha
        if "hora" in user_input_lower or "fecha" in user_input_lower:
            current_time = get_current_time_internet()
            additional_info += f"La hora/fecha actual es: {current_time}\n"
        # Clima
        if "clima" in user_input_lower or "tiempo" in user_input_lower:
            words = user_input_lower.split()
            place = None
            if "en" in words:
                idx = words.index("en")
                if idx+1 < len(words):
                    place = words[idx+1]
            if place:
                weather_info = get_weather(place)
                additional_info += f"Clima en {place}: {weather_info}\n"
        # Noticias
        if "noticias" in user_input_lower:
            news_info = get_news()
            additional_info += f"Noticias:\n{news_info}\n"
        # Lugares cercanos
        if "cercana" in user_input_lower or "cercano" in user_input_lower:
            address = "milan #4 de izcalli piramide"
            results = search_places_osm(address, query="cafe")
            additional_info += f"Lugares cercanos:\n{results}\n"
        # Imágenes
        keywords_imagen = ["imagen", "foto", "picture", "photo", "image", "pic"]
        if any(k in user_input_lower for k in keywords_imagen):
            # Sacar la palabra clave solicitada
            requested_object = extract_image_keyword(user_input) # Por ejemplo "perro", "gato"
            img_path, preview_url = download_image(requested_object)
            if img_path:
                additional_info += f"Aquí tienes la imagen solicitada (vista previa): {preview_url}\n"
                additional_info += f"![imagen](imagen_descargada.jpg)\n"
                # Comprobar relevancia
                found, top5 = check_image_relevance(img_path, requested_object)
                if found:
                    additional_info += f"La imagen parece contener algo relacionado con '{requested_object}'.\n"
                else:
                    additional_info += f"La imagen descargada no parece coincidir exactamente con '{requested_object}'. Top predicciones: {top5}\n"
            else:
                additional_info += "No pude encontrar o descargar la imagen.\n"

    prompt = build_prompt(
        user_name=state['user_name'],
        chatbot_name=state['chatbot_name'],
        story_context=state['story_context'],
        conversation_history=state['conversation_history'],
        user_input=user_input + "\n" + additional_info,
        language=state['language'],
        internet_enabled=internet_enabled
    )

    device = model.device
    inputs = processor(text=prompt, return_tensors="pt").to(device)

    with torch.inference_mode():
        output = model.generate(
            **inputs,
            min_new_tokens=min_new_tokens,
            max_new_tokens=max_new_tokens,
            temperature=adjusted_temperature,
            top_p=float(top_p),
            repetition_penalty=adjusted_repetition_penalty,
            do_sample=True,
            pad_token_id=processor.tokenizer.eos_token_id,
            no_repeat_ngram_size=3
        )

    result = processor.decode(output[0])
    if state['chatbot_name'] + ":" in result:
        response_candidate = result.split(f"{state['chatbot_name']}:")[-1].strip()
    else:
        response_candidate = result.strip()

    state['conversation_history'].append({"role":"user", "content":f"{state['user_name']}: {user_input}"})
    state['conversation_history'].append({"role":"assistant", "content":f"{state['chatbot_name']}: {response_candidate}"})

    # Ahora devolvemos la conversación entera en el nuevo formato que espera gr.Chatbot (type='messages'):
    messages = []
    for msg in state['conversation_history']:
        # msg es algo como {"role":"assistant","content":"Asistente: respuesta..."}
        # Ya tenemos role y content, solo se devuelven igual
        messages.append({"role": msg["role"], "content": msg["content"]})

    return messages, state

def reset_conversation():
    return [], None

def like_response(state):
    if state is not None:
        state['reward_score'] = state.get('reward_score', 0.0) + 1.0
    return state

def dislike_response(state):
    if state is not None:
        state['punishment_score'] = state.get('punishment_score', 0.0) + 1.0
    return state

def main():
    with gr.Blocks() as demo:
        gr.Markdown("## Chatbot MultiAlpha con Verificación de Imagen")
        chatbot_display = gr.Chatbot(
            label="Historial de la Conversación",
            height=500,
            show_label=True,
            type='messages'
        )

        state = gr.State()
        with gr.Row():
            submit_btn = gr.Button("Enviar")
            reset_btn = gr.Button("Reiniciar Conversación")
            like_btn = gr.Button("👍")
            dislike_btn = gr.Button("👎")
            internet_toggle = gr.Checkbox(label="Buscar en Internet", value=False)

        user_input = gr.Textbox(label="Tu mensaje", placeholder="Escribe aquí tu mensaje", lines=2)
        user_name = gr.Textbox(label="Tu nombre (Usuario)", placeholder="Ej: David")
        chatbot_name = gr.Textbox(label="Nombre del Chatbot", placeholder="Ej: Isabella")
        story_context = gr.Textbox(label="Contexto o Historia Inicial", placeholder="Contexto inicial de la charla", lines=3)
        seed_input = gr.Textbox(label="Semilla (opcional)", placeholder="Número entero para reproducir resultados")
        max_new_tokens = gr.Slider(label="Máx Tokens de Respuesta", minimum=1, maximum=300, step=10, value=150)
        temperature = gr.Slider(label="Temperature", minimum=0.1, maximum=1.0, step=0.05, value=0.3)
        top_p = gr.Slider(label="Top-p", minimum=0.1, maximum=1.0, step=0.05, value=0.9)
        repetition_penalty = gr.Slider(label="Penalización por Repetición", minimum=1.0, maximum=2.0, step=0.05, value=1.2)

        def handle_submit(*args):
            return asyncio.run(generate_response(*args))

        submit_btn.click(
            handle_submit,
            inputs=[user_input, user_name, chatbot_name, story_context, seed_input, max_new_tokens, temperature, top_p, repetition_penalty, state, internet_toggle],
            outputs=[chatbot_display, state]
        )

        reset_btn.click(fn=reset_conversation, inputs=[], outputs=[chatbot_display, state])
        like_btn.click(fn=like_response, inputs=[state], outputs=[state])
        dislike_btn.click(fn=dislike_response, inputs=[state], outputs=[state])

    # Para crear un link público:
    demo.launch(share=True)

if __name__ == "__main__":
    main()
